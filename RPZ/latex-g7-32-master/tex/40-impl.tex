\chapter{Технологический раздел}
\label{cha:impl}
\section{Выбор базы данных}
На этапе выбора базы данных были два варианта.
\subsection{Hypergraph}
HyperGraphDB — это расширяемая, портативная, распределенная, встраиваемая система общего назначения со свободным (open-source) механизмом хранения данных. Эта система разработана специально для проектов использующих возможности искусственного интеллекта и семантического вэба и может использоваться как встраиваемая, объектно-ориентированная база данных для проектов любого масштаба.\cite{HG}
Основным преимуществом Hypergraph была поддержка OWL. Однако, у проекта были проблемы с документацией и не было API для языков кроме java из-за было принято решение отказаться от этого продукта.
\subsection{Neo4j} 
Neo4j — это NoSQL база данных, ориентированная на хранение графов. Преимуществом продукта является декларативный язык запросов Cypher.\\
Помимо этого Neo4j предоставляет API на Python, обширную документацию, программу поддержки начинающих разработчиков, удобный Web интерфейс для свой базы данных и т.д. Однако,Neo4j нативно не поддерживает OWL, однако из-за прочих преимуществ была выбрана именно Neo4j. 
\section{Заполнение Базы данных}
\subsection{OWL IDE}
Для разработки онтологии необходим определённый инструментарий. В нашем случае был выбран Protege.\\
Protégé — это свободный, открытый редактор онтологий и фреймворк для построения баз знаний.
Платформа Protégé поддерживает два основных способа моделирования онтологий посредством редакторов Protégé-Frames и Protégé-OWL. Онтологии, построенные в Protégé, могут быть экспортированы во множество форматов, включая RDF (RDF Schema), OWL и XML Schema.
\subsection{OWL API}
Для работы с нашей онтологией в программе необходимо было использовать OWL Api, однако полноценного API под Python не оказалось, потому пришлось использовать RDFlib, предоставляющий возможности реализованные в RDF, которых по большей части хватило для решения прикладных задач.
\subsection{TMDB}
Было рассмотрено 3 варианта получения данных для заполнения БД.
\begin{enumerate}
\item Вручную.
\item Случайная генерация.
\item Получить из Web.
\end{enumerate}
Первый вариант отпал из-за нерационального использования человекочасов. Второй вариант отпал из-за последующих проблем с проверкой правильности работы программы. Третий вариант делится на два подварианта.\\
\begin{enumerate}
\item Парсинг данных с сайтов.
\item Использование API
\end{enumerate}
После некоторых поисков, был найден API для tmdb под python, и первый вариант отпал из-за излишней сложности. Данная библиотека возвращает данные по запросу уже в формате словаря, что облегчает дальнейшую работу.

\subsection {Neo4j API}
Для работы с базой данных также необходим API. Существует несколько библиотек на Python предоставляющих такой интерфейс, после небольшого изучения было решено выбрать "neo4j-rest-client" так как это хорошодокументированная библиотека, предоставляющая возможность работы как через обёртку так и через запросы на Cypher, что и необходимо для описываемого приложения.
\section{Анализ естественного языка}
\subsection{NLTK}
Для работы с естественным языком был выбран NLTK.
Библиотека NLTK, или NTLK — пакет библиотек и программ для символьной и статистической обработки естественного языка, написанных на языке программирования Python. Содержит графические представления и примеры данных. Сопровождается обширной документацией, включая книгу с объяснением основных концепций, стоящих за теми задачами обработки естественного языка, которые можно выполнять с помощью данного пакета. 

\subsection{Парсинг}
парсинг предложения в NLTK может осуществляться несколькими путями, мы коснёмся трёх
\begin{enumerate}
\item Составление Грамматики
\item Malt Parser
\item Stanford Parser
\end{enumerate}
Первый вариант отбрасывается, т.к. для контекстно-независимых грамматик он почти не подходит и требует много знаний.
\subsubsection{Malt Parser}
Синтаксический парсер написанный на Java. Основывается на машинном обучении, для парсинга использует ряд алгоритмов (Nivre, Convington, Stack,Planar, 2-Planar). Возвращает синтаксическое дерево. Проблема этого парсера заключается в скудной документации. Огромным плюсом этого парсера является наличие предобученных моделей, что позволяет новичкам сразу приступить к анализу текста.
\subsubsection{Stanford Parser}
 Синтаксический парсер написанный на Java. Также основывается на машинном обучении. Но возвращает данные не только в виде дерева, но и в виде графа, более удобного в обработке. Обладает обширной документацией и также предоставляет предобученные выборки на ряд языков. 
 \subsubsection{SyntaxNet}
 Синтаксический анализатор основанный на технологии TensorFlow. Также использует машинное обучение. Нет документации, по-умолчанию есть предобученная модель для русского языка.
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "rpz"
%%% End:
